{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed9a77f-abda-44d0-85ba-41c95cd9ef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation import deeplabv3_resnet50, deeplabv3\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from data_manager import create_modified_crop_labels\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695d2fdb-b7e7-4226-a331-5d37d82a719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = deeplabv3.DeepLabV3_ResNet50_Weights.COCO_WITH_VOC_LABELS_V1\n",
    "model = deeplabv3_resnet50(num_classes=5)\n",
    "\n",
    "\n",
    "\n",
    "# Get the original conv1 layer\n",
    "original_conv = model.backbone.conv1\n",
    "\n",
    "# Create a new conv1 layer with 6 input channels\n",
    "new_conv = torch.nn.Conv2d(\n",
    "    in_channels=18,\n",
    "    out_channels=original_conv.out_channels,\n",
    "    kernel_size=original_conv.kernel_size,\n",
    "    stride=original_conv.stride,\n",
    "    padding=original_conv.padding,\n",
    "    bias=original_conv.bias is not None,\n",
    ")\n",
    "\n",
    "model.backbone.conv1 = new_conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a512a7b-b765-429d-ade1-b10ea0313c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CropDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data.astype(float)\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Fixed mapping for known labels\n",
    "        self.label_map = {\n",
    "            -1: 0,  # background\n",
    "            1: 1,   # corn\n",
    "            5: 2,   # soybean\n",
    "            23: 3,  # spring wheat\n",
    "            176: 4  # grassland/pasture\n",
    "        }\n",
    "        self.num_classes = 5  # 5 classes including background\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get the image and label\n",
    "        image = self.data[idx, :, :, :-1]  # All bands except last one (label)\n",
    "        label = self.data[idx, :, :, -1]   # Last band is the label\n",
    "        \n",
    "        # Scale first 18 bands by 0.0001 and clip to [0,1]\n",
    "        image[:, :, :18] = np.clip(image[:, :, :18] * 0.0001, 0, 1)\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        image = torch.from_numpy(image).float()\n",
    "        \n",
    "        # Map labels to 0 to 4 range\n",
    "        label = np.vectorize(self.label_map.get)(label)\n",
    "        label = torch.from_numpy(label).long()\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4d4bd6-a614-43d6-84a0-a9b6a167b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('./training_data/train_patches.npy')\n",
    "valid_data = np.load('./training_data/val_patches.npy')\n",
    "test_data = np.load('./training_data/test_patches.npy')\n",
    "\n",
    "unchanged_crops = [1, 5, 23, 176]\n",
    "train_data = create_modified_crop_labels(train_data, unchanged_crops=unchanged_crops)\n",
    "valid_data = create_modified_crop_labels(valid_data, unchanged_crops=unchanged_crops)\n",
    "test_data = create_modified_crop_labels(test_data, unchanged_crops=unchanged_crops)\n",
    "\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CropDataset(train_data)\n",
    "val_dataset = CropDataset(valid_data)\n",
    "test_dataset = CropDataset(test_data)\n",
    "\n",
    "# Print number of classes\n",
    "print(f\"Number of classes: {train_dataset.num_classes}\")\n",
    "print(f\"Label mapping: {train_dataset.label_map}\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "# Print dataset sizes and sample shapes\n",
    "print(f\"\\nTraining samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")\n",
    "\n",
    "# Print shape of a single sample\n",
    "sample_image, sample_label = next(iter(train_loader))\n",
    "print(f\"\\nImage shape: {sample_image.shape}\")\n",
    "print(f\"Label shape: {sample_label.shape}\")\n",
    "print(f\"Unique labels in sample: {torch.unique(sample_label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e675e1b5-0abc-47ef-a184-340f20e1385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "\n",
    "# Training function\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total_pixels = 0\n",
    "    \n",
    "    # Add tqdm progress bar\n",
    "    pbar = tqdm(train_loader, desc='Training')\n",
    "    for images, labels in pbar:\n",
    "        # Move data to device\n",
    "        images = images.permute(0, 3, 1, 2).to(device)  # Change to (B, C, H, W)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)['out']\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total_pixels += labels.numel()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{(predicted == labels).float().mean().item():.4f}'\n",
    "        })\n",
    "    \n",
    "    return total_loss / len(train_loader), correct / total_pixels\n",
    "\n",
    "# Validation function\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total_pixels = 0\n",
    "    \n",
    "    # Add tqdm progress bar\n",
    "    pbar = tqdm(val_loader, desc='Validation')\n",
    "    with torch.no_grad():\n",
    "        for images, labels in pbar:\n",
    "            # Move data to device\n",
    "            images = images.permute(0, 3, 1, 2).to(device)  # Change to (B, C, H, W)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)['out']\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total_pixels += labels.numel()\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{(predicted == labels).float().mean().item():.4f}'\n",
    "            })\n",
    "    \n",
    "    return total_loss / len(val_loader), correct / total_pixels\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "best_val_acc = 0.0\n",
    "\n",
    "# Add tqdm for epochs\n",
    "epoch_pbar = tqdm(range(num_epochs), desc='Epochs')\n",
    "for epoch in epoch_pbar:\n",
    "    # Training\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validation\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step()\n",
    "    \n",
    "    # Update epoch progress bar\n",
    "    epoch_pbar.set_postfix({\n",
    "        'train_loss': f'{train_loss:.4f}',\n",
    "        'train_acc': f'{train_acc:.4f}',\n",
    "        'val_loss': f'{val_loss:.4f}',\n",
    "        'val_acc': f'{val_acc:.4f}'\n",
    "    })\n",
    "    \n",
    "    # Save best model\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(f'\\nNew best model saved with validation accuracy: {val_acc:.4f}')\n",
    "\n",
    "# Load best model for testing\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Test the model\n",
    "test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "print(f'\\nTest Results:')\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4682cd8c-f16e-4dbc-91cb-66c8ad6d1d37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bc9de0-c9fd-45ff-a579-c8f4f539e127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c774c56-bea6-4f7e-abc5-0c62fe4eb989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f967cf3f-9045-4972-8172-274efba4ac45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d20de-6a4f-453b-904a-c28aa22118a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
